{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2024-11-22T17:24:33.384405Z",
     "iopub.status.busy": "2024-11-22T17:24:33.384112Z",
     "iopub.status.idle": "2024-11-22T17:24:39.996206Z",
     "shell.execute_reply": "2024-11-22T17:24:39.995387Z",
     "shell.execute_reply.started": "2024-11-22T17:24:33.384378Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43837</th>\n",
       "      <td>Many people remember the Waco standoff that oc...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "43837  Many people remember the Waco standoff that oc...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "df=pd.read_csv(r\"D:\\GthubFiles\\Recommendation-System\\data\\IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T17:24:40.003696Z",
     "iopub.status.busy": "2024-11-22T17:24:40.003486Z",
     "iopub.status.idle": "2024-11-22T17:25:31.259787Z",
     "shell.execute_reply": "2024-11-22T17:25:31.258971Z",
     "shell.execute_reply.started": "2024-11-22T17:24:40.003674Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9abe6203a84d23a543caa9af127a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43de09ce8bd1400aa3d907e569e8ccdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertForSequenceClassification: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier', 'dropout_37']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68327ba48c24456879d9839eb605463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T17:25:31.261227Z",
     "iopub.status.busy": "2024-11-22T17:25:31.260986Z",
     "iopub.status.idle": "2024-11-22T17:25:31.264728Z",
     "shell.execute_reply": "2024-11-22T17:25:31.263994Z",
     "shell.execute_reply.started": "2024-11-22T17:25:31.261202Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T17:25:31.266368Z",
     "iopub.status.busy": "2024-11-22T17:25:31.266046Z",
     "iopub.status.idle": "2024-11-22T17:25:31.312904Z",
     "shell.execute_reply": "2024-11-22T17:25:31.312359Z",
     "shell.execute_reply.started": "2024-11-22T17:25:31.266333Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def cat2num(value):\n",
    "    if value=='positive': \n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "    \n",
    "df['sentiment']  =  df['sentiment'].apply(cat2num)\n",
    "train = df[:45000]\n",
    "test = df[45000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T17:25:31.321544Z",
     "iopub.status.busy": "2024-11-22T17:25:31.321278Z",
     "iopub.status.idle": "2024-11-22T17:25:32.024237Z",
     "shell.execute_reply": "2024-11-22T17:25:32.023423Z",
     "shell.execute_reply.started": "2024-11-22T17:25:31.321510Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def convert_data_to_examples(train, test, review, sentiment): \n",
    "    train_InputExamples = train.apply(lambda x: InputExample(guid=None,\n",
    "                                                          text_a = x[review], \n",
    "                                                          label = x[sentiment]), axis = 1)\n",
    "\n",
    "    validation_InputExamples = test.apply(lambda x: InputExample(guid=None, \n",
    "                                                          text_a = x[review], \n",
    "                                                          label = x[sentiment]), axis = 1,)\n",
    "  \n",
    "    return train_InputExamples, validation_InputExamples\n",
    "\n",
    "train_InputExamples, validation_InputExamples = convert_data_to_examples(train,  test, 'review',  'sentiment')\n",
    "                                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T17:25:32.030188Z",
     "iopub.status.busy": "2024-11-22T17:25:32.029962Z",
     "iopub.status.idle": "2024-11-22T17:25:32.039474Z",
     "shell.execute_reply": "2024-11-22T17:25:32.038791Z",
     "shell.execute_reply.started": "2024-11-22T17:25:32.030165Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\n",
    "    features = [] \n",
    "\n",
    "    for e in tqdm(examples):\n",
    "        input_dict = tokenizer.encode_plus(\n",
    "            e.text_a,\n",
    "            add_special_tokens=True,    \n",
    "            max_length=max_length,    \n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            pad_to_max_length=True, \n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n",
    "        features.append(InputFeatures( input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label) )\n",
    "\n",
    "    def gen():\n",
    "        for f in features:\n",
    "            yield (\n",
    "                {\n",
    "                    \"input_ids\": f.input_ids,\n",
    "                    \"attention_mask\": f.attention_mask,\n",
    "                    \"token_type_ids\": f.token_type_ids,\n",
    "                },\n",
    "                f.label,\n",
    "            )\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n",
    "        (\n",
    "            {\n",
    "                \"input_ids\": tf.TensorShape([None]),\n",
    "                \"attention_mask\": tf.TensorShape([None]),\n",
    "                \"token_type_ids\": tf.TensorShape([None]),\n",
    "            },\n",
    "            tf.TensorShape([]),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "DATA_COLUMN = 'review'\n",
    "LABEL_COLUMN = 'sentiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T17:25:32.040949Z",
     "iopub.status.busy": "2024-11-22T17:25:32.040625Z",
     "iopub.status.idle": "2024-11-22T17:29:22.820790Z",
     "shell.execute_reply": "2024-11-22T17:29:22.820167Z",
     "shell.execute_reply.started": "2024-11-22T17:25:32.040919Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/45000 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "100%|██████████| 45000/45000 [03:50<00:00, 195.07it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n",
    "train_data = train_data.shuffle(100).batch(32).repeat(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T17:29:22.824442Z",
     "iopub.status.busy": "2024-11-22T17:29:22.824212Z",
     "iopub.status.idle": "2024-11-22T17:29:48.189651Z",
     "shell.execute_reply": "2024-11-22T17:29:48.188747Z",
     "shell.execute_reply.started": "2024-11-22T17:29:22.824418Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:25<00:00, 197.36it/s]\n"
     ]
    }
   ],
   "source": [
    "validation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\n",
    "validation_data = validation_data.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T17:29:48.195652Z",
     "iopub.status.busy": "2024-11-22T17:29:48.195420Z",
     "iopub.status.idle": "2024-11-22T18:15:38.461478Z",
     "shell.execute_reply": "2024-11-22T18:15:38.460704Z",
     "shell.execute_reply.started": "2024-11-22T17:29:48.195627Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2814/2814 [==============================] - 1367s 486ms/step - loss: 0.2435 - accuracy: 0.8985 - val_loss: 0.2788 - val_accuracy: 0.8968\n",
      "Epoch 2/2\n",
      "2814/2814 [==============================] - 1362s 484ms/step - loss: 0.0699 - accuracy: 0.9763 - val_loss: 0.3599 - val_accuracy: 0.8988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7eea289a8b10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
    "\n",
    "model.fit(train_data, epochs=2, validation_data=validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T18:16:54.055952Z",
     "iopub.status.busy": "2024-11-22T18:16:54.055620Z",
     "iopub.status.idle": "2024-11-22T18:17:31.836131Z",
     "shell.execute_reply": "2024-11-22T18:17:31.835422Z",
     "shell.execute_reply.started": "2024-11-22T18:16:54.055923Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model.save('tf_model', save_format='tf')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T18:26:37.730942Z",
     "iopub.status.busy": "2024-11-22T18:26:37.730619Z",
     "iopub.status.idle": "2024-11-22T18:26:37.734604Z",
     "shell.execute_reply": "2024-11-22T18:26:37.733822Z",
     "shell.execute_reply.started": "2024-11-22T18:26:37.730908Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred_sentences = ['worst movie of my life, will never watch movies from this series', 'Wow, blew my mind, what a movie by Marvel, animation and story is amazing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T18:26:43.136002Z",
     "iopub.status.busy": "2024-11-22T18:26:43.135681Z",
     "iopub.status.idle": "2024-11-22T18:26:43.221590Z",
     "shell.execute_reply": "2024-11-22T18:26:43.220913Z",
     "shell.execute_reply.started": "2024-11-22T18:26:43.135975Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worst movie of my life, will never watch movies from this series :  Negative\n",
      "Wow, blew my mind, what a movie by Marvel, animation and story is amazing :  Positive\n"
     ]
    }
   ],
   "source": [
    "tf_batch = tokenizer(pred_sentences, max_length=128, padding=True, truncation=True, return_tensors='tf')   \n",
    "tf_outputs = model(tf_batch)                                  \n",
    "tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)      \n",
    "labels = ['Negative','Positive']\n",
    "label = tf.argmax(tf_predictions, axis=1)\n",
    "label = label.numpy()\n",
    "for i in range(len(pred_sentences)):\n",
    "    print(pred_sentences[i], \": \", labels[label[i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
